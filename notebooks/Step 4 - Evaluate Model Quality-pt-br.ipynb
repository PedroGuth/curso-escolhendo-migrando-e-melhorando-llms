{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# üöÄ **Passo 4: Avaliando a Qualidade das Respostas**\n",
       "\n",
       "## **Aula 4.1: Por Que Qualidade √© Importante?**\n",
       "\n",
       "---\n",
       "\n",
       "### **T√°, mas o que √© avalia√ß√£o de qualidade?**\n",
       "\n",
       "Imagina que voc√™ pediu um hamb√∫rguer num restaurante. O gar√ßom trouxe em 2 minutos (r√°pido!), mas quando voc√™ mordeu, tava cru por dentro! Velocidade sem qualidade n√£o serve pra nada. √â exatamente isso que vamos avaliar aqui - n√£o s√≥ se o modelo √© r√°pido, mas se ele faz um trabalho BOM! üòÑ\n",
       "\n",
       "**Por que avalia√ß√£o de qualidade √© importante?**\n",
       "\n",
       "Um modelo pode ser super r√°pido e barato, mas se ele gera resumos que n√£o fazem sentido ou perdem informa√ß√µes importantes, de que adianta? √â como ter um funcion√°rio que trabalha r√°pido mas faz tudo errado - n√£o √© √∫til pra ningu√©m!\n",
       "\n",
       "### **Entendendo a Avalia√ß√£o LLM-as-a-Judge**\n",
       "\n",
       "LLM-as-a-Judge funciona assim:\n",
       "\n",
       "1. **Pega** as respostas do seu modelo junto com respostas de refer√™ncia (verdade absoluta)\n",
       "2. **Usa** um modelo avaliador especializado pra julgar a qualidade\n",
       "3. **Fornece** scores padronizados em dimens√µes como corre√ß√£o, completude e estilo\n",
       "\n",
       "Essa abordagem oferece v√°rias vantagens sobre avalia√ß√£o humana tradicional:\n",
       "- **Consist√™ncia**: Aplica os mesmos padr√µes em todas as respostas\n",
       "- **Escalabilidade**: Pode avaliar milhares de respostas rapidamente\n",
       "- **Objetividade**: Reduz vi√©s humano no processo\n",
       "- **Reprodutibilidade**: Produz resultados consistentes pra mesmos inputs\n",
       "\n",
       "### **Nossa Abordagem de Avalia√ß√£o**\n",
       "\n",
       "Pra esse workshop, vamos:\n",
       "1. **Formatar** as respostas geradas no Passo 3 pra avalia√ß√£o\n",
       "2. **Criar** jobs de avalia√ß√£o separados pra cada modelo\n",
       "3. **Fazer upload** dos datasets pro S3 pra processamento\n",
       "4. **Configurar** e iniciar os jobs de avalia√ß√£o\n",
       "5. **Armazenar** refer√™ncias dos jobs pra an√°lise no pr√≥ximo passo\n",
       "\n",
       "Vamos come√ßar garantindo que temos as depend√™ncias necess√°rias instaladas:\n",
       "\n",
       "---\n",
       "\n",
       "**üñºÔ∏è Sugest√£o de imagem**: Um juiz com martelo avaliando respostas de IA"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üõ†Ô∏è IMPORTANDO AS FERRAMENTAS NECESS√ÅRIAS\n",
       "import boto3\n",
       "import json\n",
       "import random\n",
       "from datetime import datetime\n",
       "from typing import List, Dict, Any, Optional\n",
       "import pandas as pd\n",
       "import glob\n",
       "import os\n",
       "from IPython.display import display\n",
       "\n",
       "# Inicializando clientes AWS\n",
       "bedrock_client = boto3.client('bedrock')\n",
       "s3_client = boto3.client('s3')\n",
       "\n",
       "print(\"‚úÖ Ferramentas importadas! Vamos avaliar a qualidade!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Pr√©-requisitos**\n",
       "\n",
       "Pra esse notebook funcionar com sucesso, voc√™ precisa de:\n",
       "\n",
       "- **Role IAM com Permiss√µes Adequadas**: Pra criar jobs de avalia√ß√£o e acessar S3\n",
       "  - _Nota: No workshop hospedado, essas roles s√£o pr√©-configuradas pra voc√™_\n",
       "  - _Pra aprendizes autodidatas: Siga as instru√ß√µes do workshop pra criar a role necess√°ria_\n",
       "- **Bucket S3**: Pra armazenar datasets de avalia√ß√£o e resultados\n",
       "  - _Nota: O workshop cria isso automaticamente com as permiss√µes corretas_\n",
       "  - _Pra aprendizes autodidatas: Crie seu pr√≥prio bucket e atualize o nome do bucket neste notebook_\n",
       "- **Modelos de Avalia√ß√£o**: Acesso a modelos como Claude Haiku/Sonnet, Amazon Nova"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ‚öôÔ∏è CONFIGURA√á√ÉO AWS\n",
       "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
       "\n",
       "ROLE_ARN = f\"arn:aws:iam::{account_id}:role/service-role/Bedrock-LLM-as-a-Judge-ExecutionRole\"\n",
       "\n",
       "BUCKET_NAME = f\"genai-evaluation-migration-bucket-{account_id}\"\n",
       "PREFIX = \"genai_migration\"\n",
       "\n",
       "print(f\"üè¢ Account ID: {account_id}\")\n",
       "print(f\"üîë Role ARN: {ROLE_ARN}\")\n",
       "print(f\"ü™£ Bucket: {BUCKET_NAME}\")\n",
       "print(f\"üìÅ Prefix: {PREFIX}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Carregando Nosso Progresso**\n",
       "\n",
       "Vamos carregar nosso dataframe de tracking do Passo 3, que cont√©m informa√ß√µes sobre nosso modelo fonte e os modelos candidatos que vamos avaliar. Esse dataframe vai servir como nosso reposit√≥rio central pra todas as m√©tricas de avalia√ß√£o durante o workshop."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üìä CARREGANDO NOSSO TRACKING\n",
       "evaluation_tracking_file = '../data/evaluation_tracking.csv'\n",
       "evaluation_tracking = pd.read_csv(evaluation_tracking_file)\n",
       "display(evaluation_tracking)\n",
       "\n",
       "print(\"\\nüí° Perfeito! Agora temos nosso plano de avalia√ß√£o carregado.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Prepara√ß√£o de Dados pra Avalia√ß√£o de Qualidade**\n",
       "\n",
       "#### **Formatando Respostas pro LLM-as-a-Judge**\n",
       "\n",
       "O LLM-as-a-Judge precisa dos dados num formato espec√≠fico. √â como preparar a comida pro juiz de um concurso culin√°rio - tem que estar na apresenta√ß√£o certa!\n",
       "\n",
       "Vamos formatar as respostas que geramos no Passo 3 pro formato que o LLM-as-a-Judge espera:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üìù FUN√á√ÉO PRA FORMATAR DADOS PRA AVALIA√á√ÉO\n",
       "def format_data_for_evaluation(model_id, output_file_path):\n",
       "    \"\"\"\n",
       "    Formata os dados de um modelo espec√≠fico pro formato do LLM-as-a-Judge.\n",
       "    √â como traduzir um documento pra uma l√≠ngua que o juiz entende!\n",
       "    \"\"\"\n",
       "    \n",
       "    try:\n",
       "        # Carregando os dados do modelo\n",
       "        model_data = pd.read_csv(output_file_path)\n",
       "        \n",
       "        # Filtrando apenas resultados bem-sucedidos\n",
       "        successful_data = model_data[model_data['status'] == 'success']\n",
       "        \n",
       "        if len(successful_data) == 0:\n",
       "            print(f\"‚ö†Ô∏è Nenhum resultado bem-sucedido encontrado para {model_id}\")\n",
       "            return None\n",
       "        \n",
       "        # Formatando pro formato do LLM-as-a-Judge\n",
       "        evaluation_data = []\n",
       "        \n",
       "        for _, row in successful_data.iterrows():\n",
       "            evaluation_entry = {\n",
       "                'prompt': row['document'],  # O documento original\n",
       "                'referenceResponse': row['referenceResponse'],  # Resposta de refer√™ncia\n",
       "                'modelResponses': [\n",
       "                    {\n",
       "                        'response': row['model_response'],  # Resposta do modelo\n",
       "                        'modelId': model_id\n",
       "                    }\n",
       "                ]\n",
       "            }\n",
       "            evaluation_data.append(evaluation_entry)\n",
       "        \n",
       "        print(f\"‚úÖ {model_id}: {len(evaluation_data)} amostras formatadas\")\n",
       "        return evaluation_data\n",
       "        \n",
       "    except Exception as e:\n",
       "        print(f\"‚ùå Erro ao formatar dados para {model_id}: {str(e)}\")\n",
       "        return None\n",
       "\n",
       "print(\"‚úÖ Fun√ß√£o de formata√ß√£o criada! Vamos preparar os dados.\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ÔøΩÔøΩ PREPARANDO DADOS PRA TODOS OS MODELOS\n",
       "print(\"ÔøΩÔøΩ PREPARANDO DADOS PRA AVALIA√á√ÉO...\")\n",
       "print(\"=\" * 50)\n",
       "\n",
       "# Encontrando todos os arquivos de sa√≠da\n",
       "output_directory = '../outputs'\n",
       "csv_files = glob.glob(os.path.join(output_directory, 'document_summarization_*.csv'))\n",
       "\n",
       "evaluation_datasets = {}\n",
       "\n",
       "for file_path in csv_files:\n",
       "    # Extraindo o nome do modelo do nome do arquivo\n",
       "    filename = os.path.basename(file_path)\n",
       "    \n",
       "    # Identificando o modelo baseado no nome do arquivo\n",
       "    if 'source_model' in filename:\n",
       "        model_id = 'source_model'\n",
       "    elif 'amazon.nova-lite' in filename:\n",
       "        model_id = 'amazon.nova-lite-v1:0'\n",
       "    elif 'claude-3-5-haiku' in filename:\n",
       "        model_id = 'us.anthropic.claude-3-5-haiku-20241022-v1:0'\n",
       "    else:\n",
       "        print(f\"‚ö†Ô∏è Modelo n√£o reconhecido em: {filename}\")\n",
       "        continue\n",
       "    \n",
       "    print(f\"\\nüéØ Processando: {model_id}\")\n",
       "    \n",
       "    # Formatando os dados\n",
       "    formatted_data = format_data_for_evaluation(model_id, file_path)\n",
       "    \n",
       "    if formatted_data:\n",
       "        evaluation_datasets[model_id] = formatted_data\n",
       "        \n",
       "        # Salvando localmente tamb√©m (pra backup)\n",
       "        local_filename = f'../outputs/quality_evaluation.{model_id}.jsonl'\n",
       "        with open(local_filename, 'w') as f:\n",
       "            for entry in formatted_data:\n",
       "                f.write(json.dumps(entry) + '\\n')\n",
       "        \n",
       "        print(f\"ÔøΩÔøΩ Dados salvos localmente: {local_filename}\")\n",
       "\n",
       "print(f\"\\n‚úÖ Total de modelos preparados: {len(evaluation_datasets)}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Upload dos Datasets pro S3**\n",
       "\n",
       "Agora vamos fazer upload dos datasets formatados pro S3. O LLM-as-a-Judge precisa dos dados no S3 pra processar. √â como enviar os documentos pro tribunal!"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ‚òÅÔ∏è FUN√á√ÉO PRA FAZER UPLOAD PRO S3\n",
       "def upload_dataset_to_s3(model_id, evaluation_data):\n",
       "    \"\"\"\n",
       "    Faz upload do dataset de avalia√ß√£o pro S3.\n",
       "    √â como enviar os documentos pro tribunal via correio!\n",
       "    \"\"\"\n",
       "    \n",
       "    try:\n",
       "        # Criando nome √∫nico pro arquivo\n",
       "        timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
       "        s3_key = f\"{PREFIX}/evaluation_datasets/{model_id.replace(':', '-')}_{timestamp}.jsonl\"\n",
       "        \n",
       "        # Convertendo dados pra JSONL\n",
       "        jsonl_content = ''\n",
       "        for entry in evaluation_data:\n",
       "            jsonl_content += json.dumps(entry) + '\\n'\n",
       "        \n",
       "        # Fazendo upload pro S3\n",
       "        s3_client.put_object(\n",
       "            Bucket=BUCKET_NAME,\n",
       "            Key=s3_key,\n",
       "            Body=jsonl_content.encode('utf-8'),\n",
       "            ContentType='application/json'\n",
       "        )\n",
       "        \n",
       "        print(f\"‚úÖ Upload conclu√≠do: s3://{BUCKET_NAME}/{s3_key}\")\n",
       "        return s3_key\n",
       "        \n",
       "    except Exception as e:\n",
       "        print(f\"‚ùå Erro no upload para {model_id}: {str(e)}\")\n",
       "        return None\n",
       "\n",
       "print(\"‚úÖ Fun√ß√£o de upload criada! Vamos enviar os dados pro S3.\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üöÄ FAZENDO UPLOAD DE TODOS OS DATASETS\n",
       "print(\"‚òÅÔ∏è FAZENDO UPLOAD DOS DATASETS...\")\n",
       "print(\"=\" * 50)\n",
       "\n",
       "s3_keys = {}\n",
       "\n",
       "for model_id, evaluation_data in evaluation_datasets.items():\n",
       "    print(f\"\\nüì§ Upload para: {model_id}\")\n",
       "    \n",
       "    s3_key = upload_dataset_to_s3(model_id, evaluation_data)\n",
       "    \n",
       "    if s3_key:\n",
       "        s3_keys[model_id] = s3_key\n",
       "        \n",
       "        # Atualizando o tracking\n",
       "        evaluation_tracking.loc[evaluation_tracking['model'] == model_id, 'quality_evaluation_output'] = s3_key\n",
       "\n",
       "print(f\"\\n‚úÖ Uploads conclu√≠dos: {len(s3_keys)} datasets\")\n",
       "print(\"\\nÔøΩÔøΩ Resumo dos uploads:\")\n",
       "for model_id, s3_key in s3_keys.items():\n",
       "    print(f\"‚Ä¢ {model_id}: {s3_key}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Configurando e Iniciando Jobs de Avalia√ß√£o**\n",
       "\n",
       "Agora vamos configurar e iniciar os jobs de avalia√ß√£o do LLM-as-a-Judge. √â como abrir os processos no tribunal!"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ‚öñÔ∏è FUN√á√ÉO PRA CRIAR JOB DE AVALIA√á√ÉO\n",
       "def create_evaluation_job(model_id, s3_key):\n",
       "    \"\"\"\n",
       "    Cria um job de avalia√ß√£o LLM-as-a-Judge pra um modelo espec√≠fico.\n",
       "    √â como abrir um processo no tribunal com todas as evid√™ncias!\n",
       "    \"\"\"\n",
       "    \n",
       "    try:\n",
       "        # Configurando o job de avalia√ß√£o\n",
       "        job_name = f\"llmaaj-{model_id.replace(':', '-').replace('.', '-')}-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
       "        \n",
       "        # Configura√ß√£o do job\n",
       "        evaluation_config = {\n",
       "            'jobName': job_name,\n",
       "            'jobDescription': f'Avalia√ß√£o de qualidade para {model_id}',\n",
       "            'roleArn': ROLE_ARN,\n",
       "            'evaluationConfig': {\n",
       "                'taskType': 'General',\n",
       "                'datasetConfig': {\n",
       "                    'datasetType': 'CustomDataset',\n",
       "                    's3Uri': f's3://{BUCKET_NAME}/{s3_key}'\n",
       "                },\n",
       "                'modelConfig': {\n",
       "                    'modelId': model_id\n",
       "                },\n",
       "                'evaluationMetrics': [\n",
       "                    'Builtin.Correctness',\n",
       "                    'Builtin.Completeness',\n",
       "                    'Builtin.ProfessionalStyleAndTone'\n",
       "                ],\n",
       "                'evaluatorConfig': {\n",
       "                    'evaluatorModelId': 'amazon.nova-pro-v1:0'\n",
       "                }\n",
       "            },\n",
       "            'outputConfig': {\n",
       "                's3Uri': f's3://{BUCKET_NAME}/{PREFIX}/evaluation_results/'\n",
       "            }\n",
       "        }\n",
       "        \n",
       "        # Criando o job\n",
       "        response = bedrock_client.create_evaluation_job(**evaluation_config)\n",
       "        \n",
       "        job_arn = response['evaluationJobArn']\n",
       "        \n",
       "        print(f\"‚úÖ Job criado: {job_name}\")\n",
       "        print(f\"ÔøΩÔøΩ ARN: {job_arn}\")\n",
       "        \n",
       "        return job_arn\n",
       "        \n",
       "    except Exception as e:\n",
       "        print(f\"‚ùå Erro ao criar job para {model_id}: {str(e)}\")\n",
       "        return None\n",
       "\n",
       "print(\"‚úÖ Fun√ß√£o de cria√ß√£o de job criada! Vamos iniciar as avalia√ß√µes.\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ÔøΩÔøΩ INICIANDO TODOS OS JOBS DE AVALIA√á√ÉO\n",
       "print(\"‚öñÔ∏è INICIANDO JOBS DE AVALIA√á√ÉO...\")\n",
       "print(\"=\" * 50)\n",
       "\n",
       "job_arns = {}\n",
       "\n",
       "for model_id, s3_key in s3_keys.items():\n",
       "    print(f\"\\nüéØ Iniciando avalia√ß√£o para: {model_id}\")\n",
       "    \n",
       "    job_arn = create_evaluation_job(model_id, s3_key)\n",
       "    \n",
       "    if job_arn:\n",
       "        job_arns[model_id] = job_arn\n",
       "        \n",
       "        # Atualizando o tracking\n",
       "        evaluation_tracking.loc[evaluation_tracking['model'] == model_id, 'quality_evaluation_jobArn'] = job_arn\n",
       "\n",
       "print(f\"\\n‚úÖ Jobs iniciados: {len(job_arns)}\")\n",
       "print(\"\\nÔøΩÔøΩ Resumo dos jobs:\")\n",
       "for model_id, job_arn in job_arns.items():\n",
       "    print(f\"‚Ä¢ {model_id}: {job_arn}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Monitorando o Status dos Jobs**\n",
       "\n",
       "Agora vamos monitorar o status dos jobs de avalia√ß√£o. √â como acompanhar o progresso dos processos no tribunal!"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ÔøΩÔøΩ FUN√á√ÉO PRA MONITORAR STATUS DOS JOBS\n",
       "def check_job_status(job_arn):\n",
       "    \"\"\"\n",
       "    Verifica o status de um job de avalia√ß√£o.\n",
       "    √â como verificar se o processo j√° foi julgado!\n",
       "    \"\"\"\n",
       "    \n",
       "    try:\n",
       "        response = bedrock_client.get_evaluation_job(jobIdentifier=job_arn)\n",
       "        status = response['status']\n",
       "        \n",
       "        return status\n",
       "        \n",
       "    except Exception as e:\n",
       "        print(f\"‚ùå Erro ao verificar status: {str(e)}\")\n",
       "        return 'ERROR'\n",
       "\n",
       "print(\"‚úÖ Fun√ß√£o de monitoramento criada! Vamos verificar os status.\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ÔøΩÔøΩ VERIFICANDO STATUS DOS JOBS\n",
       "print(\"ÔøΩÔøΩ STATUS DOS JOBS DE AVALIA√á√ÉO:\")\n",
       "print(\"=\" * 50)\n",
       "\n",
       "for model_id, job_arn in job_arns.items():\n",
       "    print(f\"\\nüéØ {model_id}:\")\n",
       "    \n",
       "    status = check_job_status(job_arn)\n",
       "    \n",
       "    if status == 'InProgress':\n",
       "        print(f\"  ÔøΩÔøΩ Status: {status} (Em andamento)\")\n",
       "    elif status == 'Completed':\n",
       "        print(f\"  ‚úÖ Status: {status} (Conclu√≠do)\")\n",
       "    elif status == 'Failed':\n",
       "        print(f\"  ‚ùå Status: {status} (Falhou)\")\n",
       "    else:\n",
       "        print(f\"  ‚ö†Ô∏è Status: {status} (Desconhecido)\")\n",
       "\n",
       "print(\"\\nüí° Os jobs podem demorar alguns minutos para completar.\")\n",
       "print(\"üí° Voc√™ pode verificar o status novamente executando esta c√©lula.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Salvando Nosso Progresso**\n",
       "\n",
       "Vamos salvar nosso dataframe atualizado com todas as informa√ß√µes dos jobs de avalia√ß√£o. Isso vai ser crucial pro pr√≥ximo passo!"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üíæ SALVANDO O TRACKING ATUALIZADO\n",
       "evaluation_tracking.to_csv('../data/evaluation_tracking.csv', index=False)\n",
       "\n",
       "print(\"‚úÖ Tracking atualizado salvo!\")\n",
       "print(\"\\nüìä RESUMO DO QUE FIZEMOS:\")\n",
       "print(f\"‚Ä¢ Modelos preparados: {len(evaluation_datasets)}\")\n",
       "print(f\"‚Ä¢ Datasets enviados pro S3: {len(s3_keys)}\")\n",
       "print(f\"‚Ä¢ Jobs de avalia√ß√£o criados: {len(job_arns)}\")\n",
       "print(f\"‚Ä¢ Arquivo salvo: ../data/evaluation_tracking.csv\")\n",
       "\n",
       "# Mostrando o status final\n",
       "display(evaluation_tracking[['model', 'quality_evaluation_jobArn', 'quality_evaluation_output']])"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Verifica√ß√£o Final dos Jobs**\n",
       "\n",
       "Vamos fazer uma verifica√ß√£o final pra ver se todos os jobs est√£o rodando corretamente:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üîç VERIFICA√á√ÉO FINAL DOS JOBS\n",
       "print(\"üîç VERIFICA√á√ÉO FINAL DOS JOBS:\")\n",
       "print(\"=\" * 40)\n",
       "\n",
       "completed_jobs = 0\n",
       "in_progress_jobs = 0\n",
       "failed_jobs = 0\n",
       "\n",
       "for model_id, job_arn in job_arns.items():\n",
       "    status = check_job_status(job_arn)\n",
       "    \n",
       "    if status == 'Completed':\n",
       "        completed_jobs += 1\n",
       "        print(f\"‚úÖ {model_id}: Conclu√≠do\")\n",
       "    elif status == 'InProgress':\n",
       "        in_progress_jobs += 1\n",
       "        print(f\"ÔøΩÔøΩ {model_id}: Em andamento\")\n",
       "    elif status == 'Failed':\n",
       "        failed_jobs += 1\n",
       "        print(f\"‚ùå {model_id}: Falhou\")\n",
       "    else:\n",
       "        print(f\"‚ö†Ô∏è {model_id}: Status desconhecido ({status})\")\n",
       "\n",
       "print(f\"\\nÔøΩÔøΩ RESUMO:\")\n",
       "print(f\"‚Ä¢ Conclu√≠dos: {completed_jobs}\")\n",
       "print(f\"‚Ä¢ Em andamento: {in_progress_jobs}\")\n",
       "print(f\"‚Ä¢ Falharam: {failed_jobs}\")\n",
       "\n",
       "if in_progress_jobs > 0:\n",
       "    print(f\"\\n‚è∞ {in_progress_jobs} jobs ainda est√£o rodando.\")\n",
       "    print(\"ÔøΩÔøΩ Voc√™ pode aguardar alguns minutos e executar esta c√©lula novamente.\")\n",
       "    print(\"ÔøΩÔøΩ Ou prosseguir para o pr√≥ximo passo e verificar os resultados depois.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Resumo do Passo 4**\n",
       "\n",
       " **Parab√©ns!** Voc√™ acabou de completar o quarto passo da nossa jornada de migra√ß√£o. Vamos recapitular o que fizemos:\n",
       "\n",
       "‚úÖ **Entendemos a import√¢ncia da qualidade**: Velocidade sem qualidade n√£o serve\n",
       "‚úÖ **Formatamos dados pra avalia√ß√£o**: Preparamos tudo pro LLM-as-a-Judge\n",
       "‚úÖ **Fizemos upload pro S3**: Enviamos os dados pro \"tribunal\"\n",
       "‚úÖ **Criamos jobs de avalia√ß√£o**: Abrimos os processos\n",
       "‚úÖ **Monitoramos o progresso**: Acompanhamos o status dos jobs\n",
       "‚úÖ **Salvamos refer√™ncias**: Tracking atualizado com ARNs dos jobs\n",
       "\n",
       "### **O Que Vem no Pr√≥ximo Passo**\n",
       "\n",
       "No pr√≥ximo notebook, vamos fazer a **compara√ß√£o final**! √â como reunir todos os ju√≠zes pra dar o veredicto final. Vamos consolidar todas as m√©tricas (lat√™ncia, qualidade e custo) e gerar um relat√≥rio completo que vai nos ajudar a tomar a decis√£o final sobre qual modelo usar.\n",
       "\n",
       "---\n",
       "\n",
       "**üí° Dica do Pedro**: Avalia√ß√£o de qualidade √© crucial! Um modelo pode ser r√°pido e barato, mas se a qualidade for ruim, voc√™ vai ter que refazer tudo depois. √â como comprar um carro barato que quebra toda semana!\n",
       "\n",
       "**üöÄ Pr√≥ximo passo**: Compara√ß√£o final e gera√ß√£o de relat√≥rio"
      ]
     }
    ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
